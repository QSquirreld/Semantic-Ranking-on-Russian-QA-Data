{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bed717de4dd09091",
   "metadata": {
    "id": "bed717de4dd09091"
   },
   "source": [
    "### Задание\n",
    "\n",
    "1. На данном датасете обучить модель https://huggingface.co/intfloat/multilingual-e5-small с помощью этого кода.\n",
    "2. Переписать код под актуальную версию sentence-transformers.\n",
    "3. Сравнить результаты"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f78b4e",
   "metadata": {
    "id": "48f78b4e"
   },
   "source": [
    "## Пример выполнения задания смотрите в мастер-классе по теме"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "CZjDfm4YG8k9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "CZjDfm4YG8k9",
    "outputId": "4369d1ff-70b8-4cb0-90f2-9c38ca8fc69c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchmetrics\n",
      "  Downloading torchmetrics-1.8.2-py3-none-any.whl.metadata (22 kB)\n",
      "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (2.0.2)\n",
      "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (25.0)\n",
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (2.8.0+cu126)\n",
      "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
      "  Downloading lightning_utilities-0.15.2-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.2.0)\n",
      "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.15.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.19.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.4.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->torchmetrics) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->torchmetrics) (3.0.2)\n",
      "Downloading torchmetrics-1.8.2-py3-none-any.whl (983 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading lightning_utilities-0.15.2-py3-none-any.whl (29 kB)\n",
      "Installing collected packages: lightning-utilities, torchmetrics\n",
      "Successfully installed lightning-utilities-0.15.2 torchmetrics-1.8.2\n"
     ]
    }
   ],
   "source": [
    "!pip install torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "WBaQlxpHE5v5",
   "metadata": {
    "id": "WBaQlxpHE5v5"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, InputExample, losses, evaluation, util\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from datasets import load_dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "from random import shuffle\n",
    "\n",
    "from statistics import mean\n",
    "from torchmetrics.functional.retrieval import retrieval_reciprocal_rank, retrieval_average_precision, \\\n",
    "    retrieval_normalized_dcg, retrieval_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "CebJopvDAt1U",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CebJopvDAt1U",
    "outputId": "6872bf4d-fe4b-40fc-b204-ae44fc93e95a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'mps' if torch.backends.mps.is_built() else 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88a2545",
   "metadata": {
    "id": "d88a2545"
   },
   "source": [
    "## Служебные функции для работы с данными"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lpW8oqjcQWvN",
   "metadata": {
    "id": "lpW8oqjcQWvN"
   },
   "outputs": [],
   "source": [
    "# удаление повторяющихся документов\n",
    "def shrink_repeated_samples(\n",
    "    queries,\n",
    "    docs,\n",
    "    labels,\n",
    "):\n",
    "    docs_was = set()\n",
    "    qs = []\n",
    "    ds = []\n",
    "    ls = []\n",
    "    for i in range(len(queries)):\n",
    "        q, d, l = queries[i], docs[i], labels[i]\n",
    "        if d in docs_was:\n",
    "            continue\n",
    "        qs.append(q)\n",
    "        ds.append(d)\n",
    "        ls.append(l)\n",
    "        docs_was.add(d)\n",
    "\n",
    "    return qs, ds, ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jvxvPc_FQWCr",
   "metadata": {
    "id": "jvxvPc_FQWCr"
   },
   "outputs": [],
   "source": [
    "# загрузка и перемешивание train\n",
    "def train_shuffled_data(from_file=False):\n",
    "    datafile = 'trainval.pkl'\n",
    "\n",
    "    if from_file:\n",
    "        with open(datafile, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        return data\n",
    "\n",
    "    good, bad = load_train_samples()\n",
    "    data = good + bad\n",
    "    shuffle(data)\n",
    "\n",
    "    with open(datafile, 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iKlF4tcUQU6-",
   "metadata": {
    "id": "iKlF4tcUQU6-"
   },
   "outputs": [],
   "source": [
    "# загрузка и перемешивание test\n",
    "def test_shuffled_data(from_file=False):\n",
    "    datafile = 'test.pkl'\n",
    "\n",
    "    if from_file:\n",
    "        with open(datafile, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        return data\n",
    "\n",
    "    good, bad = load_test_samples()\n",
    "    data = good + bad\n",
    "\n",
    "\n",
    "    with open(datafile, 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NViTPAASQT9s",
   "metadata": {
    "id": "NViTPAASQT9s"
   },
   "outputs": [],
   "source": [
    "# формирование input example\n",
    "def train_examples():\n",
    "    data = train_shuffled_data(from_file=False)\n",
    "    data = data[:25000]\n",
    "\n",
    "    trainval = []\n",
    "    for question, document, cos in data:\n",
    "        trainval.append(\n",
    "            InputExample(texts=[question, document], label=cos)\n",
    "        )\n",
    "\n",
    "    return trainval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1IMrBcI1QS5J",
   "metadata": {
    "id": "1IMrBcI1QS5J"
   },
   "outputs": [],
   "source": [
    "# загрузка тестовых примеров\n",
    "def load_test_samples():\n",
    "    _, test = _load_dataset()\n",
    "\n",
    "    questions = test['question'].tolist()\n",
    "    contexts = test['answer'].tolist()\n",
    "\n",
    "    return _inflate_with_negative_samples(\n",
    "        questions=questions,\n",
    "        contexts=contexts,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "OSoGiXQSQR4u",
   "metadata": {
    "id": "OSoGiXQSQR4u"
   },
   "outputs": [],
   "source": [
    "# загрузка train\n",
    "def load_train_samples():\n",
    "    train, _ = _load_dataset()\n",
    "\n",
    "    questions = train['question'].tolist()\n",
    "    contexts = train['answer'].tolist()\n",
    "\n",
    "    return _inflate_with_negative_samples(\n",
    "        questions=questions,\n",
    "        contexts=contexts,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2Q-NoqgGQQ46",
   "metadata": {
    "id": "2Q-NoqgGQQ46"
   },
   "outputs": [],
   "source": [
    "# генерация негативных примеров (негативное семплирование)\n",
    "def _inflate_with_negative_samples(\n",
    "    questions,\n",
    "    contexts,\n",
    "    delta=30,\n",
    "):\n",
    "    good_q_c_cos = list(zip(questions, contexts, [1.0] * len(questions)))\n",
    "    bad_q_c_cos = []\n",
    "    n = len(good_q_c_cos)\n",
    "\n",
    "    for i in range(n):\n",
    "        cur_q, cur_c, _ = good_q_c_cos[i]\n",
    "        next_q, next_c, _ = good_q_c_cos[(i + delta) % n]\n",
    "        if next_c != cur_c:\n",
    "            bad_q_c_cos.append((cur_q, next_c, 0.0))\n",
    "\n",
    "    return good_q_c_cos, bad_q_c_cos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lkRD-fljQP1t",
   "metadata": {
    "id": "lkRD-fljQP1t"
   },
   "outputs": [],
   "source": [
    "# загрузка датасета\n",
    "def _load_raw_dataset(from_file=False):\n",
    "    raw_dataset = 'raw_dataset.pkl'\n",
    "    if from_file:\n",
    "        with open(raw_dataset, 'rb') as f:\n",
    "            df = pickle.load(f)\n",
    "    else:\n",
    "        df = load_dataset(\"Den4ikAI/russian_instructions_2\")\n",
    "        df['train'] = df['train'].select(range(50000))\n",
    "        with open(raw_dataset, 'wb') as f:\n",
    "            pickle.dump(df, f)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "VNC-GlAgQOwT",
   "metadata": {
    "id": "VNC-GlAgQOwT"
   },
   "outputs": [],
   "source": [
    "# разбиение на train, test\n",
    "def _load_dataset():\n",
    "    df = _load_raw_dataset()\n",
    "    raw_data = df['train'].to_pandas()\n",
    "    train, test = train_test_split(raw_data, test_size=0.2, random_state=42)\n",
    "\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbx2DqTxI1uO",
   "metadata": {
    "id": "dbx2DqTxI1uO"
   },
   "source": [
    "## Метрики \"из коробки\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "JVm77kQ7GsRY",
   "metadata": {
    "id": "JVm77kQ7GsRY"
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, models\n",
    "\n",
    "def raw_bi_encoder():\n",
    "    word_embedding_model = models.Transformer('intfloat/multilingual-e5-small', max_seq_length=256)\n",
    "    pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension()) # дополнительно используем слой пулинга\n",
    "    # для получения векторного представления текста целиком, а не токенов\n",
    "\n",
    "    bi_encoder = SentenceTransformer(\n",
    "        modules=[word_embedding_model, pooling_model],\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "    return bi_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "G_r4QizmG7iW",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 333,
     "referenced_widgets": [
      "61d2cb3c8cc0421e9e3b83e4d7a0e007",
      "15fb08ca14d54019855c834e61e32f09",
      "c17a77e3d77945af8ba9f864045ed8e5",
      "ab7517def99c434589738b6a5ddf7491",
      "4b3f17c35dfd45c0b81b6cf1c09235c4",
      "30daf2e4991148ee8153db6a5a79ae0e",
      "6a80dd3493a7401d9b5b40c901e6777a",
      "612a12a3c8c44421be77671ea8fae4fa",
      "0c03a903a6374072863043974840fc14",
      "f14b35c6a3c948a6981e3c738652a109",
      "2d95dc41910147ecaa739128c8b93b30",
      "7f0acb3f4142455589f1ea494866df05",
      "0786b201991b4a4bbcaf7c5f4c7f9248",
      "3328a10c9269492f9becf4014061e9e4",
      "e39700d5459d41fd8bc8be17415568b5",
      "ae47a688759f4123bc7e2e9c2ca611d5",
      "89369e3dae864ef6b94d20b16f23c5cc",
      "e760dcf0b4214ad59c2b55500ac99959",
      "b0678b05ee154a14ab7ac2a9c3bb4d98",
      "97d747008a4e4df98dd4a7f4804c5da7",
      "40e05de9dfb944c88c356e633fec3fab",
      "03316b599dfa44e9b5d824f48d1532d0",
      "c24d72bc740541ddb2ecd2c9edcdccd9",
      "bf2a8826add24179a428f3a3240dece8",
      "1673983ab6ae4d8db8514276fca3422f",
      "116b510aa9474020a4685b3feabecf47",
      "66f6fa754e8749149409ff366a594844",
      "0710be30395c42b2ad89e03c132b7659",
      "b9ccfddcc39e40cea29045170d24a526",
      "adc5800bc52c4d89b267aea76359e0ed",
      "331943db74b143fdb846e25931a295d4",
      "1429dc5617ce4801b301770d03b39bf2",
      "c0ad14c8c08a4a3681b2f797e89f9b77",
      "2898b2393aa8440ca62d9d8a81273fa9",
      "9cf240efc56b485c93093b285d7b5930",
      "4fb3bc02a6cb46b19238d7e67b2ebe3e",
      "20700d18a92a4c1fb8da51edf4950f60",
      "3ceac026392f4c32a0644e75d313d886",
      "d8fe6677712541c5aef804b6afa19493",
      "800f994b9ba84c4080b010b19af5d46e",
      "70db205619c6465390e1e28bf78ee9f3",
      "c881b7c0651f4fb1aa3eafdec0b5fc0f",
      "ec6ab4c243964f2c9444c824456bf7d6",
      "e34149066ec54172b0055a03a08fee4d",
      "aa982b286e3b4ac980456f7919e96614",
      "baa8ce9ed00a47058c1e1b67c9d735c3",
      "57df72e9794f481c8c95fd9291c2f3c4",
      "2932b99383254e5bba7029af1e32e3f7",
      "5cf8637bc7184a7db885c348e429d960",
      "472d2245aaeb4e649bc6061b09fcd437",
      "0c88c497f14645a1a93cc413f286009e",
      "f5d79334fb33406297f704c38944cdde",
      "d16c4c012b4a48878b6b9e4449c37ae4",
      "74bdaf6cd6254c79b2938d47769979bf",
      "7ac6c5dedf9a4b5ab331a041de78655c",
      "444303e2b65c479abe5cc6292df40a63",
      "981d2a69286a48cc8855ffe1d470c19a",
      "96de137757184aefa9255be6250038a8",
      "c63e80243aca4c94ad63df3e612e77e2",
      "df7c263c8cd0413588a6039ab2c20728",
      "4be6dadce92b410aa88c9e63f0188af5",
      "3a73dc7eaf3d44038bd7a0ccfa8f448b",
      "132dfbbc1fa84ec6861aa05519b56b57",
      "796b51b52641476ebef4c0ea8a6ed134",
      "f2ea324e4988409da8576ff80ade6a9a",
      "11e7d177076b4d17818c9368796cc7fe"
     ]
    },
    "id": "G_r4QizmG7iW",
    "outputId": "ab1ac988-a3dd-4ae8-d956-242601adff81"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61d2cb3c8cc0421e9e3b83e4d7a0e007",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/655 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f0acb3f4142455589f1ea494866df05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/471M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c24d72bc740541ddb2ecd2c9edcdccd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/443 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2898b2393aa8440ca62d9d8a81273fa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa982b286e3b4ac980456f7919e96614",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "444303e2b65c479abe5cc6292df40a63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/167 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bi_encoder = raw_bi_encoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Fw-C5qCYJQ-E",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fw-C5qCYJQ-E",
    "outputId": "7fdb5094-e8e2-46c5-972d-1666f0db31e3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False, 'architecture': 'BertModel'})\n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bi_encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "H7pcSf7nHpOP",
   "metadata": {
    "id": "H7pcSf7nHpOP"
   },
   "source": [
    "Метрики близости без дообучения на test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1lAGxKP3S1ID",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 113,
     "referenced_widgets": [
      "04661c1e80e24900946c6ad91c2281e8",
      "af1511e000d6463a876c45c092cf95d7",
      "99deaf3a4f564b8ca0aff61d575db6c1",
      "1860bf3b496749c59c39c3be7a86dab7",
      "175e256c78f0434ba94807e8620f3aff",
      "260966d6672c42c6970ef76f327a3afc",
      "2e8cc56bc3d344e08dc8ef8b904244d3",
      "cf635b607d3b4a86b720a273960606fb",
      "5cd7287668004e13b52e0f814a52acd8",
      "5c8fb0d55e2a4e1e800d06b3a9d940d4",
      "b1709408a03f42108d61bee6560a18cb",
      "69d460b1573e4c47b080afbbef85e664",
      "52fb7f0f84b043bab847473af407f514",
      "c4a72986ddc845e7878b92cf01f16c8b",
      "4a40f0c67d50472a8912f94010935ba0",
      "543f119ecdd1423ca0c53d65ff8a10a1",
      "c043ddc7300d4f0dbddc7add92fc499c",
      "657c26384adb414494c828f92efd42fa",
      "dda6a9561e10474b9f42bbbf1a765c0d",
      "28ea449d3c9f4914932f7f5a61107574",
      "b25bce861c9e4e9a8696f5e8242df957",
      "c2aed8620524425e9812ffc9cbcda61c",
      "90e5ac3ab8354ba0ac5494a6d8f6c6a1",
      "3539095bdc8e4ef49a5b6f1d56396ac3",
      "aa22b7e83f0f4326b9647795ecf697d2",
      "194e7dbb8a7842dbaadfdea155fd9cc9",
      "8d4c10fe9fd942b98e89db6df3bdcbdb",
      "5cc58de580e34bdc9fd86aa231356fd2",
      "61f594f38834419783582e9f533550ee",
      "f37189d7d8d347158ae563d44528e37f",
      "aeeec9540f6343de9363dfb0e56222f2",
      "87658bd067504605885bc834de31c865",
      "1460d9c499f7424bb590bed5dea8a42c"
     ]
    },
    "id": "1lAGxKP3S1ID",
    "outputId": "24d2b38e-3352-454e-b5ce-bbee0501155d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04661c1e80e24900946c6ad91c2281e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69d460b1573e4c47b080afbbef85e664",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dataset.jsonl:   0%|          | 0.00/233M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90e5ac3ab8354ba0ac5494a6d8f6c6a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/237281 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train = train_shuffled_data(from_file=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066hyVWsHPyL",
   "metadata": {
    "id": "066hyVWsHPyL"
   },
   "outputs": [],
   "source": [
    "train_questions, train_contexts, train_coss = zip(*train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7J5JZdROHWnA",
   "metadata": {
    "id": "7J5JZdROHWnA"
   },
   "outputs": [],
   "source": [
    "evaluator = evaluation.EmbeddingSimilarityEvaluator(train_questions, train_contexts, train_coss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eS6JOofJHXvc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eS6JOofJHXvc",
    "outputId": "c25eb933-ffcd-429d-b0c4-5a7e092f7f33"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pearson_cosine': 0.8811549276560331, 'spearman_cosine': 0.8568613438699423}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bi_encoder.evaluate(evaluator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7Q3h9PUXHoTm",
   "metadata": {
    "id": "7Q3h9PUXHoTm"
   },
   "source": [
    "Метрики близости без дообучения на test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gboywMMLHjAQ",
   "metadata": {
    "id": "gboywMMLHjAQ"
   },
   "outputs": [],
   "source": [
    "bi_encoder = raw_bi_encoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "raqUUS__TCgq",
   "metadata": {
    "id": "raqUUS__TCgq"
   },
   "outputs": [],
   "source": [
    "test = test_shuffled_data(from_file=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ubN4qO3Xd9OT",
   "metadata": {
    "id": "ubN4qO3Xd9OT"
   },
   "outputs": [],
   "source": [
    "shuffle(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qQahwHMGHgxd",
   "metadata": {
    "id": "qQahwHMGHgxd"
   },
   "outputs": [],
   "source": [
    "n_test_samples = 1000\n",
    "test_questions, test_contexts, test_coss = zip(*test[:n_test_samples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "V3501C0bHhjU",
   "metadata": {
    "id": "V3501C0bHhjU"
   },
   "outputs": [],
   "source": [
    "evaluator = evaluation.EmbeddingSimilarityEvaluator(test_questions, test_contexts, test_coss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "FRCU8rdNHl4n",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FRCU8rdNHl4n",
    "outputId": "7ff62d14-0c77-4fa9-8c89-36a9d21edce7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pearson_cosine': 0.8744010056847706, 'spearman_cosine': 0.8550462825683011}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bi_encoder.evaluate(evaluator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iDjXQEV5HqzG",
   "metadata": {
    "id": "iDjXQEV5HqzG"
   },
   "source": [
    "Ожидаемо на необученной модели метрики для обучающих и тестовых данных примерно совпадают"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795e93f2090efad5",
   "metadata": {
    "id": "795e93f2090efad5"
   },
   "source": [
    "# Дообучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4SMlEA6J8d1W",
   "metadata": {
    "id": "4SMlEA6J8d1W"
   },
   "outputs": [],
   "source": [
    "train_examples = train_examples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jgr-BoMjHtYr",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jgr-BoMjHtYr",
    "outputId": "f0c79c09-c2a3-4285-a067-98211eac40f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'guid': '', 'texts': ['Какие продукты лучше всего употреблять для здорового питания сердца?', 'Лучшие продукты для здорового питания сердца включают фрукты, овощи, цельнозерновые продукты, нежирные белки и обезжиренные молочные продукты. Употребление в пищу большого количества растительных продуктов, богатых клетчаткой, таких как бобовые, орехи, семена и цельнозерновые продукты, может помочь снизить уровень холестерина. Кроме того, сокращение потребления насыщенных жиров и трансжиров важно для поддержания здорового уровня сахара в крови и поддержания здоровья сердечно-сосудистой системы.'], 'label': 1.0}\n"
     ]
    }
   ],
   "source": [
    "print(train_examples[0].__dict__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8B4IbINpHzeA",
   "metadata": {
    "id": "8B4IbINpHzeA"
   },
   "source": [
    "Позитивный семпл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3OTR8Mt98lId",
   "metadata": {
    "id": "3OTR8Mt98lId"
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_examples,\n",
    "    shuffle=True,\n",
    "    batch_size=32,\n",
    "    collate_fn=bi_encoder.smart_batching_collate # special batch + tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PDcOcmME9UT7",
   "metadata": {
    "id": "PDcOcmME9UT7"
   },
   "outputs": [],
   "source": [
    "train_loss_set = losses.CosineSimilarityLoss(bi_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-Urd01YAIkLZ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-Urd01YAIkLZ",
    "outputId": "8e2c8b1a-8769-49a1-ff76-da0f07421fbe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CosineSimilarityLoss(\n",
       "  (model): SentenceTransformer(\n",
       "    (0): Transformer({'max_seq_length': 256, 'do_lower_case': False, 'architecture': 'BertModel'})\n",
       "    (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "  )\n",
       "  (loss_fct): MSELoss()\n",
       "  (cos_score_transformation): Identity()\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loss_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "O1QLcG6DIkeZ",
   "metadata": {
    "id": "O1QLcG6DIkeZ"
   },
   "source": [
    "Добавили лосс к модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "-vX-dnhHR6ln",
   "metadata": {
    "id": "-vX-dnhHR6ln"
   },
   "source": [
    "Формирование батча"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "B1OnX7vNEA3w",
   "metadata": {
    "id": "B1OnX7vNEA3w"
   },
   "outputs": [],
   "source": [
    "(query_batch, context_batch), labels = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "K1_miXsrILFA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K1_miXsrILFA",
    "outputId": "273d67e4-8cdb-443c-ef1c-fabe5c21ec43"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 78]), torch.Size([32, 256]), torch.Size([32]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_batch['input_ids'].shape, context_batch['input_ids'].shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "VmsIiJ_1H2jb",
   "metadata": {
    "id": "VmsIiJ_1H2jb"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yt7RYuTaR0k7",
   "metadata": {
    "id": "yt7RYuTaR0k7"
   },
   "source": [
    "Запуск дообучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "p-C2A-nSHmdM",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 349,
     "referenced_widgets": [
      "7ccb3106bb6b4cd291b8884dec7731bc",
      "1ccae41f05834480871157c5c2baa8f0",
      "f23031063c9644a7b82ac62d55ff650d",
      "eaac291167ac4139bda0da981425a7c1",
      "0231f2d59aa24eb4b1220096b15cde44",
      "0139514208844f63ba1a213b739707d2",
      "737912c0a88b4f00af2479ec18439e3b",
      "723d6f9a8d8f434b9ffcb51bedc81629",
      "a26a847d6f9448918661e5d55e0f47fa",
      "8dc4488e6c674ac6b846617923dac189",
      "635544a20f9e4f44b77a6daccfbe1e6e"
     ]
    },
    "id": "p-C2A-nSHmdM",
    "outputId": "bc2406de-e437-4c2d-bb14-e444ec68a161"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ccb3106bb6b4cd291b8884dec7731bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2346' max='2346' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2346/2346 25:28, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Pearson Cosine</th>\n",
       "      <th>Spearman Cosine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.242400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>782</td>\n",
       "      <td>0.242400</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.909104</td>\n",
       "      <td>0.853199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.066800</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.052100</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1564</td>\n",
       "      <td>0.052100</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.918491</td>\n",
       "      <td>0.853657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.047000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2346</td>\n",
       "      <td>0.047000</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.923353</td>\n",
       "      <td>0.854768</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bi_encoder.fit(\n",
    "    train_objectives=[(train_loader, train_loss_set)],\n",
    "    output_path='qa/results',\n",
    "    epochs=3,\n",
    "    evaluator=evaluator,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "CRVCpG0xKnnv",
   "metadata": {
    "id": "CRVCpG0xKnnv"
   },
   "source": [
    "## Загрузка чекпоинта"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tcFqyP-3SijM",
   "metadata": {
    "id": "tcFqyP-3SijM"
   },
   "outputs": [],
   "source": [
    "finetuned_bi_encoder = SentenceTransformer('qa/results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "FbA1WC58F2hc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FbA1WC58F2hc",
    "outputId": "891fe4d9-0396-4a0f-eeec-3b4f5441f775"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pearson_cosine': 0.9233526188449115, 'spearman_cosine': 0.8547684728308436}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finetuned_bi_encoder.evaluate(evaluator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f52aaa19b97faa1",
   "metadata": {
    "id": "1f52aaa19b97faa1"
   },
   "source": [
    "# Получение предсказаний модели и меток\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wpjUyEWRTZ2F",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wpjUyEWRTZ2F",
    "outputId": "152b8c62-16f8-4d4c-f5ea-12e4cdd91b16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docs count before shrinking: 1000\n",
      "docs count without duplicates: 1000\n"
     ]
    }
   ],
   "source": [
    "test = test_shuffled_data(from_file=True)\n",
    "n_test_samples = 1000\n",
    "test_questions, test_contexts, labels = zip(*test[:n_test_samples])\n",
    "\n",
    "print(f'docs count before shrinking: {len(test_contexts)}')\n",
    "\n",
    "queries, docs, labels = shrink_repeated_samples(\n",
    "    queries=test_questions,\n",
    "    docs=test_contexts,\n",
    "    labels=labels,\n",
    ")\n",
    "\n",
    "print(f'docs count without duplicates: {len(test_contexts)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "JmtAnNi8Kjls",
   "metadata": {
    "id": "JmtAnNi8Kjls"
   },
   "source": [
    "Получение эмбеддингов (кодирование)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3FgbGZ86GBgL",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "99f52735a0c24fefb00d04a0641d4e3c",
      "70c5564b330145e4ba44ac0582cc6788",
      "107d572167ec45018531aa8eb8cd1919",
      "049fd2e3a2d94d81a506bc7a5a56dba6",
      "f9be59899544462d9be1a3232a322d9a",
      "5f031e0124834679a1be8216c2b2372c",
      "ba1ac7f1032a4d19a422edc105e28144",
      "55c5b736b4ca451988bfd24924df1a5a",
      "68d9f200a6e6452a9a7d91edd749a7f1",
      "2565a9d2e8564af789f8ac56ed09c370",
      "17ee5f2103d84cdfa01ac20478073616"
     ]
    },
    "id": "3FgbGZ86GBgL",
    "outputId": "e985e211-ddae-44f1-8e21-5733fa5c201d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99f52735a0c24fefb00d04a0641d4e3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "context_embs = finetuned_bi_encoder.encode(\n",
    "    test_contexts,\n",
    "    convert_to_tensor=True,\n",
    "    show_progress_bar=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rTkt_onGGEbm",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "4502f13820ac4219a743ef633b2e798d",
      "ab14e60258af44009692dc3638bd1050",
      "7f3710bc318f418a97747d8f230726ea",
      "a386237cdcd147d98ef4ff96f4faa819",
      "0d14f874fc3e425d8f6b55cad1b50100",
      "4252068df5ce442196ced1087b8a2a70",
      "9148203d26494b2f8f20a77eaa89a211",
      "b156b96e9ed74213aac4bd10ffeb8061",
      "f4293b724062451a9a0dee8e8c7e0858",
      "e20770dd893f4b96b420dbbd97b3667b",
      "f1bbbcb3d5a14e11a4cea0b143cf976d"
     ]
    },
    "id": "rTkt_onGGEbm",
    "outputId": "f1baa4ac-dfad-4183-8556-369927d4299e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4502f13820ac4219a743ef633b2e798d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "question_embs = finetuned_bi_encoder.encode(\n",
    "    test_questions,\n",
    "    convert_to_tensor=True,\n",
    "    show_progress_bar=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "g2xdl8LrKtpX",
   "metadata": {
    "id": "g2xdl8LrKtpX"
   },
   "source": [
    "# Семантический поиск"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "UnOVz3XmGLSJ",
   "metadata": {
    "id": "UnOVz3XmGLSJ"
   },
   "outputs": [],
   "source": [
    "cos_scores = util.semantic_search(question_embs, context_embs, top_k=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "XvTPVZenK7lo",
   "metadata": {
    "id": "XvTPVZenK7lo"
   },
   "outputs": [],
   "source": [
    "top_k = 5\n",
    "q_idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "UOPUNCK-GNQ-",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UOPUNCK-GNQ-",
    "outputId": "11528ef6-8c4d-44cd-eca0-0e3448b1fdfa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'corpus_id': 660, 'score': 0.9122371673583984}, {'corpus_id': 0, 'score': 0.8851485252380371}, {'corpus_id': 985, 'score': 0.8700286746025085}, {'corpus_id': 997, 'score': 0.8678606748580933}, {'corpus_id': 513, 'score': 0.8397399187088013}]\n"
     ]
    }
   ],
   "source": [
    "print(cos_scores[q_idx][:top_k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "QRw4qY9XGPB4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QRw4qY9XGPB4",
    "outputId": "0e044c22-bf60-49f2-bfe6-fd06155947c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  У меня проблемы с весом. Есть ли что-то, что я могу сделать, чтобы потерять часть этого?\n",
      "\n",
      "corpus id:  660\n",
      "Document 1: Cosine Similarity is 0.912:\n",
      "\n",
      "Вы можете попытаться сосредоточиться на здоровом питании и регулярно заниматься спортом. Это поможет вам оставаться активным и сжечь лишние калории. Кроме того, обязательно пейте много воды и высыпайтесь каждую ночь. Эти шаги могут помочь вам поддерживать более здоровый вес с течением времени.\n",
      "\n",
      "corpus id:  0\n",
      "Document 2: Cosine Similarity is 0.885:\n",
      "\n",
      "Вы можете попробовать регулярно заниматься спортом. Выполнение физических упражнений, таких как бег, плавание или езда на велосипеде, поможет вам сжечь калории и ускорить метаболизм. Вы также можете сосредоточиться на здоровом питании, уменьшив количество обработанных продуктов и сладких закусок в своем рационе, а также добавив больше фруктов и овощей. Кроме того, употребление большого количества воды и достаточный сон важны для поддержания здорового веса.\n",
      "\n",
      "corpus id:  985\n",
      "Document 3: Cosine Similarity is 0.870:\n",
      "\n",
      "Конечно! Важно помнить, что похудение — это процесс, требующий терпения и самоотверженности. Вы должны сосредоточиться на здоровой пище и регулярно заниматься спортом. Старайтесь каждый день вносить небольшие изменения в свой рацион, например, добавляйте больше фруктов и овощей или уменьшайте количество обработанных продуктов, которые вы едите. Кроме того, обязательно высыпайтесь и пейте много воды в течение дня. Упражнения также могут быть очень полезными для похудения. Найдите занятия, которые вам нравятся, и бросьте себе вызов. Наконец, не забывайте оставаться позитивным и мотивированным!\n",
      "\n",
      "corpus id:  997\n",
      "Document 4: Cosine Similarity is 0.868:\n",
      "\n",
      "Лучший способ похудеть и удержать вес — это составить план, который работает для вас, сочетая здоровые привычки питания с регулярными физическими упражнениями. Соблюдение сбалансированной диеты, богатой фруктами, овощами, цельнозерновыми продуктами, нежирными белками и нежирными молочными продуктами, может помочь вам дольше чувствовать себя сытым и снизить общее потребление калорий. Кроме того, ежедневная умеренная физическая активность не менее 30 минут поможет вам сжечь больше калорий, а также улучшит ваше здоровье. Наконец, употребление большого количества воды в течение дня поможет вам оставаться энергичным и сосредоточенным на своих целях.\n",
      "\n",
      "corpus id:  513\n",
      "Document 5: Cosine Similarity is 0.840:\n",
      "\n",
      "Самый эффективный способ похудеть – составить план здорового питания и регулярно заниматься спортом. Употребление в пищу большего количества цельных продуктов, таких как фрукты, овощи, нежирные белки и цельнозерновые продукты, может помочь вам дольше чувствовать себя сытым, сохраняя при этом свой бюджет калорий. Кроме того, регулярные физические упражнения, такие как ходьба или езда на велосипеде, могут увеличить ваш метаболизм и сжечь лишние калории. Наконец, убедитесь, что высыпаетесь каждую ночь, чтобы поддерживать свои усилия и поддерживать себя в тонусе в течение дня.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Question: ', test_questions[q_idx])\n",
    "print()\n",
    "\n",
    "for no, ir in enumerate(cos_scores[q_idx][:top_k]):\n",
    "    corpus_id = ir[\"corpus_id\"]\n",
    "    print('corpus id: ', corpus_id)\n",
    "    print(f'Document {no + 1}: Cosine Similarity is {ir[\"score\"]:.3f}:\\n\\n{test_contexts[corpus_id]}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0c4e7784ac8b14",
   "metadata": {
    "id": "bb0c4e7784ac8b14"
   },
   "source": [
    "# Расчёт метрик: Recall@5, MRR, MAP, NDCG@10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f93ggdOGQ3Y",
   "metadata": {
    "id": "8f93ggdOGQ3Y"
   },
   "outputs": [],
   "source": [
    "def build_target_mask_for_i(i, n):\n",
    "    target_mask = [False] * n\n",
    "    target_mask[i] = True\n",
    "    return target_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "GlEcrJ0VGRpL",
   "metadata": {
    "id": "GlEcrJ0VGRpL"
   },
   "outputs": [],
   "source": [
    "def build_pred_mask_for_i(\n",
    "    cos_scores,\n",
    "    i,\n",
    "    n,\n",
    "):\n",
    "    pred_mask = [0.0] * n\n",
    "    qi_scores = cos_scores[i]\n",
    "\n",
    "    for docid_score in qi_scores:\n",
    "        doc_id = docid_score['corpus_id']\n",
    "        score = docid_score['score']\n",
    "        pred_mask[int(doc_id)] = score\n",
    "\n",
    "    return pred_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd1b776",
   "metadata": {
    "id": "cbd1b776"
   },
   "source": [
    "### До дообучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wMp5WsOFTTZT",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "417981e1b35b491cbdea4a17d31bdb3c",
      "1da2db96648947d7b7dc62b609c4fac2",
      "35027798924745e4aa499a6ee3eddea8",
      "d262de4cd293420090db2095814ca296",
      "3821567b58714c70ac955986741cb82a",
      "022c4812bb4540a2b9ea98feb7a90869",
      "de5c179227af4521bdb81d0e8d50e296",
      "791ad92e86704e5391bbb76b818ec98e",
      "7369423ebd2746aa9a3f502b7753ed10",
      "750fbd2a05344a8b9c39fe1d096b4e39",
      "2fc9215f2d6049088ecd56998224f182",
      "3d16930410684cb499a99d540226766c",
      "336f8cfdaa2c4facb4ad808b633f08da",
      "48812460c90f4524b30a26d5296b75c8",
      "2f1089ae913e483c8017d5f9c71ba3b2",
      "b77990fc55df421e8b41ab6159cd98e9",
      "7009623188db43baa37165ac3045de33",
      "c13229ef8f5c4595bae00cfd74fc3201",
      "a9bf726b3a3c4657a27f26502d8d9d80",
      "f28e5318db304212a180b81a0b4dcc64",
      "e0764d295fd64362afcc6ab56a3e5991",
      "4e3e1b6b699e41ca87f9921affc4ff31"
     ]
    },
    "id": "wMp5WsOFTTZT",
    "outputId": "d23a491f-061b-4be0-8a65-bbd18cb75a5e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "417981e1b35b491cbdea4a17d31bdb3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d16930410684cb499a99d540226766c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "init_context_embs = bi_encoder.encode(\n",
    "    test_contexts,\n",
    "    convert_to_tensor=True,\n",
    "    show_progress_bar=True,\n",
    ")\n",
    "\n",
    "init_question_embs = bi_encoder.encode(\n",
    "    test_questions,\n",
    "    convert_to_tensor=True,\n",
    "    show_progress_bar=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3NrBnACrTZoC",
   "metadata": {
    "id": "3NrBnACrTZoC"
   },
   "outputs": [],
   "source": [
    "init_cos_scores = util.semantic_search(init_question_embs, init_context_embs, top_k=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2wfY1Q6VTLxd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2wfY1Q6VTLxd",
    "outputId": "b7520064-b247-44fc-c1c1-682fb214ede6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean recall5@891:  0.886\n",
      "mean mrr:  0.7941333337575197\n",
      "mean rmAP:  0.7941333337575197\n",
      "mean ndcg10@891:  0.8264232175350189\n"
     ]
    }
   ],
   "source": [
    "r5s = []\n",
    "mrrs = []\n",
    "rmaps = []\n",
    "ndcgs = []\n",
    "\n",
    "for i in range(len(test_questions)):\n",
    "    pred = build_pred_mask_for_i(init_cos_scores, i=i, n=len(test_contexts))\n",
    "    target = build_target_mask_for_i(i=i, n=len(test_contexts))\n",
    "\n",
    "    pred = torch.tensor(pred)\n",
    "    target = torch.tensor(target)\n",
    "\n",
    "    r5 = retrieval_recall(preds=pred, target=target, top_k=5).item()\n",
    "    mrr = retrieval_reciprocal_rank(preds=pred, target=target, top_k=5).item()\n",
    "    rmap = retrieval_average_precision(preds=pred, target=target, top_k=5).item()\n",
    "    ndcg = retrieval_normalized_dcg(preds=pred, target=target, top_k=10).item()\n",
    "\n",
    "    r5s.append(r5)\n",
    "    mrrs.append(mrr)\n",
    "    rmaps.append(rmap)\n",
    "    ndcgs.append(ndcg)\n",
    "\n",
    "print(f'mean recall5@{len(docs)}: ', mean(r5s))\n",
    "print('mean mrr: ', mean(mrrs))\n",
    "print('mean rmAP: ', mean(rmaps))\n",
    "print(f'mean ndcg10@{len(docs)}: ', mean(ndcgs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4185d90",
   "metadata": {
    "id": "b4185d90"
   },
   "source": [
    "### После дообучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9BxzGXTCTMn9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9BxzGXTCTMn9",
    "outputId": "bb7ff966-2974-4634-cfe7-280086613fb5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean recall5@891:  0.886\n",
      "mean mrr:  0.7941333337575197\n",
      "mean rmAP:  0.7941333337575197\n",
      "mean ndcg10@891:  0.8264232175350189\n"
     ]
    }
   ],
   "source": [
    "r5s = []\n",
    "mrrs = []\n",
    "rmaps = []\n",
    "ndcgs = []\n",
    "\n",
    "for i in range(len(test_questions)):\n",
    "    pred = build_pred_mask_for_i(cos_scores, i=i, n=len(test_contexts))\n",
    "    target = build_target_mask_for_i(i=i, n=len(test_contexts))\n",
    "\n",
    "    pred = torch.tensor(pred)\n",
    "    target = torch.tensor(target)\n",
    "\n",
    "    r5 = retrieval_recall(preds=pred, target=target, top_k=5).item()\n",
    "    mrr = retrieval_reciprocal_rank(preds=pred, target=target, top_k=5).item()\n",
    "    rmap = retrieval_average_precision(preds=pred, target=target, top_k=5).item()\n",
    "    ndcg = retrieval_normalized_dcg(preds=pred, target=target, top_k=10).item()\n",
    "\n",
    "    r5s.append(r5)\n",
    "    mrrs.append(mrr)\n",
    "    rmaps.append(rmap)\n",
    "    ndcgs.append(ndcg)\n",
    "\n",
    "print(f'mean recall5@{len(docs)}: ', mean(r5s))\n",
    "print('mean mrr: ', mean(mrrs))\n",
    "print('mean rmAP: ', mean(rmaps))\n",
    "print(f'mean ndcg10@{len(docs)}: ', mean(ndcgs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2zA20I9ufnJa",
   "metadata": {
    "id": "2zA20I9ufnJa"
   },
   "source": [
    "# Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "BbX_NqSDfpeV",
   "metadata": {
    "id": "BbX_NqSDfpeV"
   },
   "source": [
    "**Метрики близости**\n",
    "\n",
    "|Метрика|Initial|Fine-Tuned|Изменение|\n",
    "|-------|-------|----------|---------|\n",
    "|Pearson (cosine)|0.874|0.923|+0.049|\n",
    "|Spearman (cosine)|0.855|0.854|-0.001|\n",
    "\n",
    "1. Метрики в целом высокие `0.85 - 0.9`\n",
    "2. Метрики высокие и \"из коробки\": `P=0.87` и `S=0.85`\n",
    "3. `Pearson` вырос на `5%`\n",
    "* Модель почти идеально предсказывает сходство вопросов и контекстов по абсолютным значениям.\n",
    "4. `Spearman` можно сказать, что `не изменился`\n",
    "* Модель изначально хорошо ранжирует пары по релевантности\n",
    "5. **Общий вывод по метрикам близости:**<br>Модель ранжирует примерно так же, но стала увереннее в своих оценках (что и видно по Pearson)\n",
    "* Модель научилась лучше приближать вероятности, не ухудшив сортировку.\n",
    "* **Fine-tuning не изменил порядок предсказаний**, но сделал значения cosine similarity более точными.\n",
    "\n",
    "**Метрики ранжирования**\n",
    "\n",
    "|Метрика|Initial|Fine-Tuned|Изменение|\n",
    "|-------|-------|----------|---------|\n",
    "|Recall5@1000|0.886|0.886|0|\n",
    "|MRR|0.794|0.794|0|\n",
    "|rmAP|0.794|0.794|0|\n",
    "|NDCG10@1000|0.826|0.826|0|\n",
    "\n",
    "1. Метрики никак не изменились<br>\n",
    "Причины:\n",
    "- Возможно дообучение было недостаточным\n",
    "    - т.к. я взял не полный датасет, а лишь его часть\n",
    "    - даже при этом модель обучалась 3 эпохи на протяжении получаса (colab ограничен😞)\n",
    "    - возможно эпох было недостаточно\n",
    "- Модель, несмотря на свой размер, уже из коробки отлично ранжирует ответы\n",
    "    - `Recall@5 = 0.886` — уже высокая метрика.\n",
    "2. В 5/5 различных вопросов, **все ответы в top-5 были верны**, отвечали либо полностью, либо относились к теме. Лишнего не было вообще."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
